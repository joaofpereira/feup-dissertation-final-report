\chapter*{Abstract}

The \textit{Smart Cities} are a future that most cities want to achieve by appealing to the citizens' participation to improve its services. The participation process is comprised of simple contributions, opinions or even validations of technological projects by the citizens. In this way, the social networks are a rich source of data where ordinary citizens publicly share their comments, and for this reason, it's resorted by many text mining projects since this information provides interesting analytics based on \textit{human-generated} data.

The extraction of information from social media texts, in this case the \textit{Twitter}, regarding the services of a \textit{smart city}, is the major topic that will be discussed here. The texts that are  obtained from a social network can sometimes be difficult to analyze, since the writing of a person is not always correct and/or coherent, such as, wrongly typing words and/or incorrect phrasal structuring, respectively. With all of this points, it's possible to slice the main problem into four sub-problems. The first one is to collect data from the social network; the second one is focused on the semantic analysis and elimination of ambiguous lexicons of the text; the third one will be the extraction of aspects from the messages and the classification of the sentiment polarity; finally, it's necessary to aggregate the results obtained into a set of indicators to categorize the founded problems.

We propose to tackle the aforementioned problems through the creation of a framework capable of collecting and extracting value from social media streams. The framework will be composed by a total of four modules, in order to solve each sub-problem mentioned above. The first one should handle social-data-collection tasks according to some user-defined heuristics. The second module should semantically analyze the text and remove ambiguities from the lexicon, using named entity linking techniques in order to filter the unrelated messages from the dataset. After this filtering, the texts will be subjected to the module of sentiment analysis to find out if its content has positive or negative value regarding some specific topics. Finally, the analytics module will aim the aggregation of the results obtained from the previously module in a set of statistical visual indicators.

The expected results in this dissertation rely heavily in the UI presented to the end-user. The knowledge derived from the text processing tasks may help ordinary users of cities services or even the responsible entities in the identification and interpretation of some problems, and, thus, the decision-making process can be easier.

%\chapter*{Resumo}

