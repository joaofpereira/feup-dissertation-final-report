\chapter{Conclusions and Future Work} \label{chap:conclusions}

\minitoc \mtcskip \noindent

\iffalse
\section{Final Remarks}

The literature review shows the main challenges across the evolution process of a city in order to be titled as \textit{smart}. Moreover, the biggest restrictions in the development of intelligent systems using social media data are enunciated as well as possible methodologies and techniques to solve it. By combining the challenges of a \textit{smart city} and the restrictions present in the analysis of text messages, in particular tweets, the problem in this dissertation was divided into three distinct ones. The solutions presented to each of the sub-problems took into consideration lacks observed in the literature review. Domain generalization in the conception of an automatic system based on both, supervised and unsupervised learning methods, and capable of collect, filter, process, aggregate and demonstrate valuable information to final entities/users is one of the identified lacks. The transportation domain also present lacks regarding discrimination of travel-related tweets using methods that take advantages from semantic and syntactic similarities in texts. The majority of works present conventional techniques such as bag-of-words, which although good performances represents high risks when facing the unstable and unexpected changes regarding the modes of transport in a real-world scenario.

Assuming the challenges identified for this dissertation as well as the previous mentioned lacks in the literature review, we propose and develop a domain-agnostic framework and test it using five different cities over the world as use cases for three distinct analysis: exploratory data analysis, travel-related classification for English and Portuguese languages and Twitter topics identification over two Brazilian megacities, Rio de Janeiro and São Paulo.

The experiment related to the characterization of topics over tweets from Brazilian cities presented promising results, however our topics classification approach might not be the most suitable because such classification should be done by experts from the area of linguistics in order to have robustness and accuracy into the identified topics. Although such limitation, we implemented a specific module for this task, integrating it in the final framework. Literature review shows potential approaches which can help to improve the model responsible for identification of topics in tweets, nonetheless it is necessary an extended period of time to implement such improvements.

Travel-related classification of tweets using a combined approach of bag-of-words and bag-of-embeddings proved that each text representation completes the other since results showed consistency and robustness over the classification performed to Portuguese texts. On the contrary, English speaking tweets do not present similar results, however, as it was previous mentioned, the bag-of-words features fed into our classification model were not robust. A further experiments proved such theory since the model was able to maintain its performance only using bag-of-embeddings as training features.

It is worth nothing that every experiment was performed having only into consideration geo-located tweets. This choice, as previously mentioned, was due to the additional information contained in this type of tweets. By analysing the location of tweets and combining it with results of the classification tasks, we might be able to characterize and study specific areas in cities, as well as identifying existent and notable patterns regarding travel-related problems and mobility dynamics.

Having all considered, it is necessary to enhance that our framework is still far of its full potential. Supporting on this, we consider it as a scalable, flexible and adaptive prototype that must improved over time since implementing supervised learning systems is a laborious and time consuming process.


\section{Contributions}

At the end of this dissertation, efforts applied are summarized in three different types of contributions.

\begin{itemize}
	\item \textbf{Scientific Contributions}
	
	 In order to test each module composing the framework, several experiments using conventional and recently text mining methods were followed. Our desire to share the advantages obtained on such experiments take us to perform three attempts of scientific contributions. The first one is about automatic classification of travel-related Portuguese speaking tweets, for the cities of Rio de Janeiro and São Paulo, and is currently under the press phase in the EPIA 2017. Attempts are performed taking into consideration different types of features in the training phase of the model, being the most accurate the one combining bag-of-words and bag-of-embedding.
	
	Further experiment reports the previous mentioned method over English speaking tweets from New York City. The final results reveal differences comparing to the Portuguese experiment. Having this considered, another approach was chosen to prove signs of overfitting in the training process, \textit{leave-one-group-out strategy}. Final remarks demonstrate the consistency of word embeddings model for hidden modes of transport classes, while bag-of-words model prove to be dependent of the examples used in the training phase. The overall experiment was submitted to the CIKM-2017 and is currently in review.
	
	Finally, the experiment regarding topic modelling is reported to the IEEE S3C 2017. There is described the use of LDA model to characterize the topic present in a tweet. Promising results were obtained after a difficult topic classification phase. The final model was then used to implement the topic modelling sub-module of the developed framework in this dissertation. It is worth noting that this contribution, similar to the previous one, is under review phase.
	
	\item \textbf{Technical Contributions}
	
	At the end of this work, we report that every implementation performed during the dissertation period will be open-sourced to help future candidates in the integration of new functionalities to the framework. Besides that, the implementation of the travel-related classification models require the conception of labeled datasets regarding the transportation domain. These datasets, containing Portuguese and English speaking tweets will be uploaded in order to fulfill the absence of public datasets, with hope of being considered a gold standard in future developments of this kind.

	\item \textbf{Applicational Contributions}
	
	The most important contributions of this dissertation are the analysis provided by the developed automatic analysis-based system. The information provide by such system can serve to support monitoring tasks in cities as well as help in future decision-making policies by the responsible entities' services. Although the final framework being presented as a prototype, with integration of new features to the system, there are infinite possibilities for its use as well as its potential for the smart cities domain.
\end{itemize}

\section{Future Work}

The dissertation purpose had as it main focus the conception of an automatic system capable of analyse real-time data streams from social media platforms in order to produce valuable information for users of services or even its responsible entities. For achieve the proposed goals, we tried to explore already consistent state-of-the-art methodologies as well as unexplored ones regarding specific domains. Since this framework can be seen as a prototype of a future complex system, several improvements can be invested here. Although already existent modules and text analysis devised, it worth noting the conjecture of a additional sentiment analysis module in order to infer the sentiment polarity value regarding specific zones where the travel-related tweets were located in, as so the overall sentiment in an identified topic.

Another important work to pursue in the future is to correlate the results of this study with official sources of transportation agencies relatively to traffic congestions and other events on the transportation network, including all modes of transports and their integration interfaces and modules. This kind of association will be useful both to validate the proposed approach as well as to improve the inference process and knowledge extraction. The automatic classifier herein presented will then be integrated into data fusion routines to enhance transportation supply and demand prediction processes alongside other sensors and sources of information.

A possible future direction to improve the topic modelling approach is the application of spatio-temporal aggregation methods under a sample of data to create more complex documents, retrain the model and verify if the results can be different taking into consideration some of the factors that distinguish both cities: demographics, culture and location. An attempt to pursue good performances using supervised LDA models also needs to be enhanced here.

Lastly, there is a need of creation of other specific models to other fields of a \textit{smart city} in order to assure equally performances for any of its fields.
\fi

\section{Final Remarks}

This work tackles the problem of extracting meaningful and actionable knowledge from user generated content in the scope of smart cities and intelligent transportation systems. We designed and developed a framework for collection, processing and mining of geo-located Tweets. More specifically, it provides functionalities for parallel collection of geo-located tweets from multiple pre-defined bounding boxes (cities or regions), including filtering of non complying tweets, text pre-processing for Portuguese and English language, topic modeling, and transportation-specific text classifiers, as well as, aggregation and data visualization.

The Twitter Streaming API has three different heuristics to collect tweets: terms-based retrieval, following the activity of users and collect all tweets inside a specific bounding-box. The final stakeholders of our framework are cities and to provide content and geographical analysis, we opt for the locations heuristic. However, we found that several retrieved tweets do not respect the pre-defined bounding-box, i.e., the limits the tweets coordinates are outside the pre-defined bounding-box. Most of previous work using geo-located tweets do not take into account this phenomenon. We designed a filtering model capable to cope with noisy geo-located tweets. This module also filters out tweets written in any language besides the pre-defined English and Portuguese languages.

To analyse the text message of tweets, we design a text analytics module which is composed by two sub-modules. These sub-modules are in charge of performing topic modelling and travel-related classification tasks. In the module responsible for characterize tweets over latent topics, we needed to submit each tweet to a pre-defined group of text pre-processing operations. Lower casing, transformation of repeated characters, removal of \textit{metadata}, punctuation. short tokens and Portuguese stop words are the pre-processing operations used to clean the text message and facilitate the identification of latent topics. With respect to the travel-related classification of tweets, we tried to combine different text representation to fed as features group in the training routine of our models. To clean and make easier the task of classification, we perform lower casing, transformation of repeated characters and removal of \textit{metadata} and Portuguese and English stop words. 

To aggregate the final results provided by the text analytics module, we used the MongoDB aggregation framework since it present high performance and scalability, dealing well with large volumes of data. Finally, the visualization of results explores a library capable of saving locally the graphical representations of results. By using this saving method, the framework only needs to execute its text and statistical analysis in specific periods of time since when a user requests for a visualization, there is no need to consult the data warehouse. Lower response time is one of the most important factors in systems dealing with high volumes of data.

To illustrate our approach we conduct an exploratory data analysis and performed experiments for each text analytics module in real-world scenarios. We performed empirical studies and implemented illustrative examples for 5 cities: Rio de Janeiro, São Paulo, New York City, London and Melbourne, comprising a total of more than 43 millions tweets in a period of 3 months. Through the exploratory data analysis we identify that more than 70\% of tweets do not have a fine-grained geographic coordinate but they refer to bounding-boxes representing large areas on each city, such as "Ipanema". This fact reduces the ability to perform thorough spatial analysis of geo-located tweets.

Our framework focuses on content analysis of geo-located tweets. We performed a topic modeling experiment for a large volume of tweets from the two most populous and active Brazilian cities, Rio de Janeiro and São Paulo. The latent topics discovered might serve as actionable information to cities helping in the monitoring of what is being talked about in its urban regions. Both Rio de Janeiro and São Paulo presented similar latent topics in which 25 of them were equal and only 2 latent topics were specific of each city, summing up a total of 29 distinct topics. It is worth to notice that our latent topic model was capable of recognize general purpose topics such as "Relationship ad Friendship" and "Personal Feelings", making us to question why Brazilian people talk about such personal subjects into social media networks.

In the experiment of travel-related tweets classification, we constructed different gold standard datasets for two distinct speaking-languages, Portuguese and English. In the features construction process, we take support of recent advanced text mining techniques such as word-embeddings. This technique enhances the semantic and syntactic similarities between text messages allowing the identification that "busão" (a Brazilian informal term for the bus transport-mode) is used in the same context that is formal term "ônibus". We have further used the embedding matrix (bag-of-embeddings) of tweets in combination with bag-of-words features to train our text classifiers. The Portuguese classification model performed very well and was able to discriminate tweets which travel terms were omitted from the training process. The classification of tweets having "Uber" and "Busão" as travel-related ones is a proof of the robustness and generalization of our model.

On the other hand, the English text classifier revealed high levels of dependency with the bag-of-words features. The training set of this model was conducted using a \gls{k-fold-cross-validation} technique since English travel-terms, such as "Walk" and "Train", have high levels of polysemy. The preliminary scores of our model were almost perfect and beacuse of that, we designed a new strategy to conduct the remainder of the experiment. By following a leave-one-group-out strategy, we verified that models trained with word embeddings features maintain their performance while models trained with bag-of-words have drastically decrease its performance. Such strategy was enough to conclude the lack of robustness in the bag-of-words features making us to decide to use of a model trained with word-embeddings into the framework implementation for English speaking cities. 

Regarding the Portuguese cities, we chose to use the model trained with both type of features: \gls{BoE} and \gls{BoW}.

%To discriminate tweets from two distinct speaking-languages, we built several datasets composed by travel-related and non-related tweets. We train our models using bag-of-embeddings and bag-of-words features to prove the complementarity of both text representations. Regarding the Portuguese text classifier, we verify high level of robustness and generalization, while the English text classifier shows that only bag-of-words are capable of providing such robustness and generalization.

\section{Contributions}
\label{seCc:contributions}
At the end of this dissertation, we summarise the contributions achieve in three main dimensions:

\begin{itemize}
	\item \textbf{Technical Contributions}
	We designed and developed an open-source framework implemented in Python programming language using the Tweepy library for collecting geo-located tweets. Our implementation allows the collection of multiple and parallel bounding-boxes (cities or regions) and it is complying with the Twitter Streaming API usage limits. We opted to use a no-SQL database (MongoDB) as data storage software which provides flexibility, scalability and adaptability to the framework. We rely on Python's LDA library fro topic modelling, Gensim library to train paragraph2vec embeddings from geo-located tweets and Sckit-learn to train the test classifiers. The framework also provide flexible aggregations and on-time visualization using the Plotly library. The framework can be used in multiple application scenarios, from different content languages to different levels of geographic granularity (streets vs cities vs regions vs countries).

	\item \textbf{Applicational Contributions}
	To the best of our knowledge this work is the first large scale comparative topic modelling study of geo-located tweets in Brazilian \textit{megacities}. We are also the first to explore the recent advances in word-embeddings with application to text classification in the scope of smart cities and intelligent transportation cities.
	
	\item \textbf{Scientific Contributions}
	We performed empirical evaluation on the applicability and robustness of word-embeddings representation as features to train a travel-related classifier of geo-located tweets. To perform these studies, we had to create new gold standard data that can be used by the community for further experimentation.
	
	The main finding of the analysis carried out were documented in papers submitted to conferences as follows. 
\end{itemize}

\section{Publications}
\label{sec:publications}
During the period of this dissertation, we published three different scientific papers in order to share our experiments' methodologies and results.

\begin{itemize}
	\item
	João Pereira, Arian Pasquali, Pedro Saleiro and Rosaldo J. F. Rossetti. {\color{blue}Transportation in Social Media: an automatic classifier for travel-related tweets}. In \emph{Portuguese Conference on Artificial Intelligence} (EPIA), 2017. In Press~\cite{pereira2017transport}.
	
	\item
	João Pereira, Arian Pasquali, Pedro Saleiro, Rosaldo J. F. Rossetti and Javier Sanchez-Medina. {\color{blue}Classifying Travel-related Tweets Using Word Embeddings}. In \emph{IEEE 20th International Conference on Intelligent Transportation Systems} (IEEE ITSC), 2017. Under review.
	
	\item
	João Pereira, Arian Pasquali, Pedro Saleiro, Rosaldo J. F. Rossetti and Nélio Cacho. {\color{blue}Characterizing Geo-located Tweets in Brazilian Megacities}. In \emph{The Third International Smart Cities Conference} (ISC2), 2017. Under review.
\end{itemize}

\section{Future Work}

The dissertation purpose had as it main focus the conception of an automatic system capable of analyse real-time data streams from social media platforms in order to produce valuable information for users of services or even its responsible entities. For achieve the proposed goals, we tried to explore already consistent state-of-the-art methodologies as well as unexplored ones regarding specific domains. Since this framework can be seen as a prototype of a future complex system, several improvements can be invested here. Although already existent modules and text analysis devised, it worth noting the conjecture of a additional sentiment analysis module in order to infer the sentiment polarity value regarding specific zones where the travel-related tweets were located in, as so the overall sentiment in an identified topic.

In this dissertation we trained word embeddings using geo-located tweets to further use such embeddings matrices as features to train our transportation text classifiers. Later we will perform an intrinsic evaluation of these word embeddings in order to publicly share benchmarks for travel-related terms as Saleiro et al.~\cite{saleiro2017embeddings} have made using general tweets to study practical aspects of this text representation.

The extension of our training and test sets is other future work to take into consideration, as well as the application of deep learning classifiers into our classification tasks.

Nonetheless, we can explore a way of predicting future events in a city or even the impact that certain transportation entities will have in specific places~\cite{saleiro2016learning} in order to monitor correctly the the agglomeration of people in these places and the roads traffic.

Another important work to pursue in the future is to correlate the results of this study with official sources of transportation agencies relatively to traffic congestions and other events on the transportation network, including all modes of transports and their integration interfaces and modules. This kind of association will be useful both to validate the proposed approach as well as to improve the inference process and knowledge extraction. The automatic classifier herein presented will then be integrated into data fusion routines to enhance transportation supply and demand prediction processes alongside other sensors and sources of information. Additionally, such correlations and inference results can be very useful as input to traffic simulation tools~\cite{passos2011towards, azevedo2015state}, and to support multi-resolution and multi-purpose transportation analysis~\cite{timoteo2010trasmapi, ferreira2008cooperative}.

A possible future direction to improve the topic modelling approach is the application of spatio-temporal aggregation methods under a sample of data to create more complex documents, retrain the model and verify if the results can be different taking into consideration some of the factors that distinguish both cities: demographics, culture and location. An attempt to pursue good performances using supervised LDA models also needs to be enhanced here.

Lastly, there is a need of creation of other specific models to other fields of a \textit{smart city} in order to assure equally performances for any of its fields. Nonetheless, this work will also be integrated into the MAS-Ter Lab framework~\cite{rossetti2007towards}, whose main objective is to support the design, evaluation, and implementation of transportation engineering solutions and smart mobility relying on the concept of Artificial Transportation Systems~\cite{rossetti2014advances}, combining both data- and model-driven methodologies.