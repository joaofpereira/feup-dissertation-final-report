\chapter{Introduction} \label{chap:intro}

\minitoc \mtcskip \noindent

\section{Scope and Motivation}\label{sec:scope_motivation}
With the rise of Social Media, people obtain and share information almost instantly on a 24/7 basis. Many research areas have tried to extract valuable insights from these large volumes of user generated content. The research areas of intelligent transportation systems and smart cities are no exception. Transforming this data into valuable information can be meaningful and useful for city governance, support traffic management and control, transportation services or even ordinary citizens wanting to be constantly informed about their cities. 

\gls{SMC} is still in the process of maturation regarding its use in the \textit{smart cities}~\cite{batty2012smart} and transportation~\cite{gal2014potential} fields; users tend to publicly share events in which they participate, as well as the ones related to the operation of the transportation network, such as accidents and other disruptions. Indeed, this type of content is also targeted by studies about opinion mining, human behavior and respective activity patterns, political issues, social communication (e.g. news websites). Such studies focus their efforts on ways of understanding what people think and talk about and transform this knowledge into actionable and meaningful content. 

The exploration of \gls{SMC} brings particular advantages, under virtually no cost, such as real-time data and content authenticity due to its human generated nature~\cite{kuflik2017automating}. The availability of this kind of data may be seen as its main advantage. Social media companies provide tools to the developers community that do not require additional costs regarding its exploration, allowing the local storage of data and the possibility of performing off-line analysis.

Among the existing social networks, Twitter is probably the most adequate for these purposes due to its microblog nature in which users publicly share short messages about their daily lifes. Twitter has already proved its value and potential in domains ranging from news detection~\cite{kn:Sankaranarayanan2009} to real-time traffic sensing~\cite{carvalho2010real}. Other social networks, such as Facebook are not so accessible as users tend to publish content within a private circle of friends. Twitter is the 11th most visited website\footnote{\url{http://www.alexa.com/topsites}} in the planet. Its community is continuously growing and, nowadays, the number of active users is about 313 million\footnote{\url{https://about.twitter.com/company}}, registering a daily average of 400 million new posts. Although only 1-2\% of all tweets published everyday are geo-located ~\cite{ikeda2013twitter}, these tweets have the advantage of having an explicit geographic relevance to the city where users published those messages.

\section{Problem Statement}\label{sec:problem}

Mining Twitter data is a laborious and time-consuming process due to the restrictions and difficulties present in its content. The informal language, the existence of slang, abbreviations, jargons and the short length of the message are some of the problems when analyzing this data. Harvesting tweets automatically and, at the same time, extracting valuable information for \textit{smart cities} and transportation domains makes the task even more complex. The lack of gold standards datasets is the most disturbing problem since we are not able to benchmark any analysis performed to these aforementioned domains.

%The main motivation behind this dissertation centers in the construction of a framework able to automatically collect, process and mine geo-located tweets providing information that may be of extremely importance and useful to the final stakeholders, namely \textit{smart cities} and transportation entities, during decision-making policies to improve their services.

The problem on focus in this dissertation is the analysis of a continuous flow of social media streams provided by Twitter. Extracting meaningful and actionable knowledge from such \gls{UGC} is a complex process which we can divide into three main different sub-problems.

First, each social network, Twitter inclusive, has its own particular specificities regarding the data collection methodology. To solve this problem, it is necessary to know which are the targets of the resulting information and which are the methods available in the collecting tools provided by social networks, as well as its limitations.

Second, the volume of data retrieved by such collecting tools is overwhelming and to automatically process and mine these data it is necessary to study what are the most valuable and less time consuming approaches to extract the desired information, useful to entities in the context of \textit{smart cities} and \textit{intelligent transportation systems}.

Finally, the previous mentioned restrictions present in Twitter message (short text, informality, existence of abbreviations, jargon, slang and idioms) require the application of specific \gls{NLP} techniques in order to facilitate the text analysis routines.

\iffalse
To analyse such streams, multiple steps composed in an iterative process are needed in order to filter out non-related content and proceed with extraction of information about a specific scenario. Here, since the target scenarios are associated to \textit{smart cities} and transportation domains, data related to it must be explored and analysed. To the best of our knowledge, there are no public datasets related to these domains and the creation of a gold standard dataset constitutes a complex endeavor, which is, for this reason, an obstacle to surpass in this dissertation. The extraction of information from social media content is another overwhelming task since it is necessary the application of several \gls{NLP} methods in order to minimize/extinct its peculiarly problems. Hence, the main problem can be divided in five distinct sub-problems:

\begin{enumerate}
	\item \textbf{Data collection method for various locations}\\Choosing a method to collect data that provides a large range of valuable information for different cities constitutes the first sub-problem.
	
	\item \textbf{Content filtering}\\It is necessary to assure that all information is fully related to the target scenario in analysis, as well as removing messages which does not brought additional information (for instance, tweets only composed by \textit{emoticons}) or are not related to the end-users expectations, i.e. if we are targeting content from a specific city, we must guarantee that such content is indeed posted when users were there.
	
	\item \textbf{Identification of topics in Twitter messages}\\The identification of topics in Twitter messages is a very important point in the analyses of the \textit{smart cities} context. This task allows the identification of what is been talked about recently and also where the conversation topics are geographically distributed.
	
	\item \textbf{Travel-related classification}\\In order to produce valuable information for the transportation services, we need to analyse the content of a message and verify if it is truly related with the domain in study. Hence, discriminate travel-related tweets is one of the sub-problems that must be tackled.
	
	\item \textbf{Data aggregation and visualization}\\The aggregation of the results provide by all other tasks is needed. This aggregation task may be continuously calculating the results in order to make the user experience easier and smooth without taking to much response time by the data visualization \gls{UI}. The graphical visualizations should be of easy interpretation by the end-user and having this in mind some qualitative and quantitative indicators may be presented.
\end{enumerate}
\fi

\section{Aim and Goals}\label{sec:aim_goals}
This thesis aims to design and develop of a research framework for text processing and semantic analysis of geo-located Tweets within a pre-defined geographical area (e.g. cities). More specifically, to practically implement such a framework we shall accomplish the following goals: 

\begin{itemize}
	\item Continuous collection of geo-located tweets from multiple bounding boxes in parallel and in compliance with Twitter API usage limits;
	
	\item Tackling Twitter Geo API inconsistencies and filtering noisy tweets;
	
	\item Implement standard text pre-processing methods for social media texts;
	
	\item Content analysis using topic modeling and comparative characterization among different bounding boxes (e.g. cities);
	
	\item Travel-related classification of tweets using supervised learning;
	
	\item Train word embeddings from geo-located tweets;
	
	\item Study the impact of word embeddings in travel-related classification;
	
	\item Creation of gold-standard data for travel-related supervised learning;
	
	\item Aggregation and visualization of results.
\end{itemize}


%Following the previous mentioned problem in Section \ref{sec:problem}, the main goal of this dissertation passes through the development of a prototype framework based on the concept of analysis. Such framework demands a solution for each of the aforementioned sub-problems, and for that reason modularity is needed in the design and implementation of the final tool. Its usability will be directed to companies or even ordinary users and should be able to provide relevant information about a specific real-world scenario under the \textit{smart cities} and transportation fields. The framework should be capable of automatically processing social media texts, more specifically, general topic detection and characterization of travel-related tweets. The following list summarizes the crucial goals behind this dissertation:

%\begin{itemize}
%	\item Extraction of valuable information from \gls{SMC} to the Transportation and \textit{Smart Cities} domains;
%	\item Designing and implementation of a framework capable of automatize the analysis process;
%	\item Application, when possible, of recent advances and technologies from the area of text analysis;
%\end{itemize}

%\medskip

%In terms of expected contributions, we hope that such generated information through the framework data analytics may be relevant both to ordinary users of a particular service and to the responsible entities in order to improve decision-making policies.

%The major goal of this thesis consists in the design and development of a research framework for text processing and semantic analysis of geo-located Tweets within a pre-defined geographical area (e.g. cities). More specifically, the framework shall accomplish the following objectives:

\section{Document Structure}\label{sec:doc_structure}
The remainder of this document is organized as follows.
Chapter~\ref{chap:sota} starts with a brief contextualization in the Smart Cities and Intelligent Transportation System domains, as well as previous related works using social media content as its basis.
The proposed framework is referenced in Chapter~\ref{chap:framework}, being each its composing modules depth described.
Experiments performed to test each module of the framework are reported in Chapter~\ref{chap:experiments}.
We end the document with Chapter~\ref{chap:conclusions} where conclusions, future work and a few final remarks are exposed.